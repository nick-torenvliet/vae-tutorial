{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Understanding Variational Autoencoders\n",
    "\n",
    "An Abridged History of Neural Networks:\n",
    "- Linear [Perceptron](https://en.wikipedia.org/wiki/Perceptron)\n",
    "- Non-linear [SVM](https://en.wikipedia.org/wiki/Support_vector_machine)\n",
    "- Perceptron w/ Activation [Neural Networks](https://wiki.pathmind.com/neural-network)\n",
    "- Activation Function [Activation Functions](https://en.wikipedia.org/wiki/Activation_function)\n",
    "- Stochastic Gradient Descent [Stochastic Gradient Descent](https://en.wikipedia.org/wiki/Stochastic_gradient_descent)\n",
    "- Shallow [Neural Network](https://en.wikipedia.org/wiki/Neural_network_(machine_learning))\n",
    "- Deep [Neural Network](https://en.wikipedia.org/wiki/AlexNet)\n",
    "\n",
    "Describing the training process on a deterministic autoencoder: \n",
    "- [Autoencoder Diagram](https://www.ibm.com/think/topics/variational-autoencoder)\n",
    "\n",
    "VAE diagram introducing the probabilistic genertive model:\n",
    "- [VAE Wiki](https://en.wikipedia.org/wiki/Variational_autoencoder)\n",
    "\n",
    "Transformers:\n",
    "- [Transformers](https://en.wikipedia.org/wiki/Transformers)\n",
    "- [Transformers](https://en.wikipedia.org/wiki/Transformer)\n",
    "- [Transformers](https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture))\n",
    "\n",
    "Diffusion:\n",
    "- [Diffusion](https://en.wikipedia.org/wiki/Diffusion_model)\n",
    "\n",
    "Academic source material:\n",
    "- [Auto-Encoding Variational Bayes](https://arxiv.org/abs/1312.6114)\n",
    "- [Variational Autoencoders Tutorial](https://arxiv.org/abs/1906.02691)\n",
    "- [Beta-VAE](https://arxiv.org/abs/1804.03599)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from scipy.stats import norm\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import make_grid as make_image_grid\n",
    "from tqdm import trange\n",
    "\n",
    "torch.manual_seed(2017) # reproducability\n",
    "sns.set_style('dark')\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Select device (MPS for Apple Silicon, CUDA for NVIDIA, else CPU)\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self,latent_dim=20,hidden_dim=500):\n",
    "        super(VAE,self).__init__()\n",
    "        self.fc_e = nn.Linear(784,hidden_dim)\n",
    "        self.fc_mean = nn.Linear(hidden_dim,latent_dim)\n",
    "        self.fc_logvar = nn.Linear(hidden_dim,latent_dim)\n",
    "        self.fc_d1 = nn.Linear(latent_dim,hidden_dim)\n",
    "        self.fc_d2 = nn.Linear(hidden_dim,784)\n",
    "            \n",
    "    def encoder(self,x_in):\n",
    "        x = F.relu(self.fc_e(x_in.view(-1,784)))\n",
    "        mean = self.fc_mean(x)\n",
    "        logvar = self.fc_logvar(x)\n",
    "        return mean, logvar\n",
    "    \n",
    "    def decoder(self,z):\n",
    "        z = F.relu(self.fc_d1(z))\n",
    "        x_out = F.sigmoid(self.fc_d2(z))\n",
    "        return x_out.view(-1,1,28,28)\n",
    "    \n",
    "    def sample_normal(self,mean,logvar):\n",
    "        sd = torch.exp(logvar*0.5)\n",
    "        e = torch.randn(sd.size(), device=device)  # Move to device\n",
    "        z = e.mul(sd).add_(mean)\n",
    "        return z\n",
    "    \n",
    "    def forward(self,x_in):\n",
    "        z_mean, z_logvar = self.encoder(x_in)\n",
    "        z = self.sample_normal(z_mean,z_logvar)\n",
    "        x_out = self.decoder(z)\n",
    "        return x_out, z_mean, z_logvar\n",
    "\n",
    "model = VAE().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Loss function\n",
    "def criterion(x_out,x_in,z_mu,z_logvar):\n",
    "    bce_loss = F.binary_cross_entropy(x_out,x_in,size_average=False)\n",
    "    kld_loss = -0.5 * torch.sum(1 + z_logvar - (z_mu ** 2) - torch.exp(z_logvar))\n",
    "    loss = (bce_loss + kld_loss) / x_out.size(0) # normalize by batch size\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Data loaders\n",
    "trainloader = DataLoader(\n",
    "    MNIST(root='./data',train=True,download=True,transform=transforms.ToTensor()),\n",
    "    batch_size=128,shuffle=True)\n",
    "testloader = DataLoader(\n",
    "    MNIST(root='./data',train=False,download=True,transform=transforms.ToTensor()),\n",
    "    batch_size=128,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "def train(model,optimizer,dataloader,epochs=15):\n",
    "    losses = []\n",
    "    for epoch in trange(epochs,desc='Epochs'):\n",
    "        for images,_ in dataloader:\n",
    "            # x_in = Variable(images)\n",
    "            x_in = images.to(device)  # Move data to device\n",
    "            optimizer.zero_grad()\n",
    "            x_out, z_mu, z_logvar = model(x_in)\n",
    "            loss = criterion(x_out,x_in,z_mu,z_logvar)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "    return losses\n",
    "\n",
    "train_losses = train(model,optimizer,trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(train_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Visualize moving average of losses\n",
    "def visualize_losses_moving_average(losses,window=50,boundary='valid',ylim=(95,125)):\n",
    "    mav_losses = np.convolve(losses,np.ones(window)/window,boundary)\n",
    "    corrected_mav_losses = np.append(np.full(window-1,np.nan),mav_losses)\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(losses)\n",
    "    plt.plot(corrected_mav_losses)\n",
    "    plt.ylim(ylim)\n",
    "    plt.show()\n",
    "\n",
    "visualize_losses_moving_average(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Testing\n",
    "def test(model,dataloader):\n",
    "    running_loss = 0.0\n",
    "    for images, _ in dataloader:\n",
    "        # x_in = Variable(images)\n",
    "        x_in = images.to(device)  # Move data to device\n",
    "        x_out, z_mu, z_logvar = model(x_in)\n",
    "        loss = criterion(x_out,x_in,z_mu,z_logvar)\n",
    "        running_loss = running_loss + (loss.item()*x_in.size(0))\n",
    "    return running_loss/len(dataloader.dataset)\n",
    "\n",
    "test_loss = test(model,testloader)\n",
    "print(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Visualize VAE input and reconstruction\n",
    "def visualize_mnist_vae(model,dataloader,num=16):\n",
    "    def imshow(img):\n",
    "        npimg = img.numpy()\n",
    "        plt.imshow(np.transpose(npimg,(1,2,0)))\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "    images,_ = next(iter(dataloader))\n",
    "    images = images[0:num,:,:].to(device)\n",
    "    x_in = Variable(images)\n",
    "    x_out,_,_ = model(x_in)\n",
    "    x_out = x_out.data\n",
    "    imshow(make_image_grid(images.cpu()))\n",
    "    imshow(make_image_grid(x_out.cpu()))\n",
    "\n",
    "visualize_mnist_vae(model,testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Train, test and visualize reconstruction using a 2D latent space\n",
    "model2 = VAE(latent_dim=2).to(device)\n",
    "optimizer2 = torch.optim.Adam(model2.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train2_losses = train(model2,optimizer2,trainloader)\n",
    "test2_loss = test(model2,testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(test2_loss)\n",
    "visualize_mnist_vae(model2,testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Visualize test data encodings on the latent space\n",
    "def visualize_encoder(model,dataloader):\n",
    "    z_means_x, z_means_y, all_labels = [], [], []\n",
    "    \n",
    "    for images,labels in iter(dataloader):\n",
    "        z_means,_ = model.encoder(Variable(images).to(device))\n",
    "        z_means_x = np.append(z_means_x,z_means[:,0].cpu().data.numpy())\n",
    "        z_means_y = np.append(z_means_y,z_means[:,1].cpu().data.numpy())\n",
    "        all_labels = np.append(all_labels,labels.numpy())\n",
    "        \n",
    "    plt.figure(figsize=(6.5,5))\n",
    "    plt.scatter(z_means_x,z_means_y,c=all_labels,cmap='inferno', s=1)\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "visualize_encoder(model2,testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Train, test and visualize reconstruction using a 3D latent space\n",
    "model3 = VAE(latent_dim=3).to(device)\n",
    "optimizer3 = torch.optim.Adam(model2.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train3_losses = train(model3,optimizer3,trainloader)\n",
    "test3_loss = test(model3,testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "def visualize_encoder_3d(model, dataloader):\n",
    "    z_means_x, z_means_y, z_means_z, all_labels = [], [], [], []\n",
    "    \n",
    "    for images, labels in iter(dataloader):\n",
    "        z_means, _ = model.encoder(Variable(images).to(device))\n",
    "        \n",
    "        z_means_x = np.append(z_means_x, z_means[:, 0].cpu().data.numpy())\n",
    "        z_means_y = np.append(z_means_y, z_means[:, 1].cpu().data.numpy())\n",
    "        z_means_z = np.append(z_means_z, z_means[:, 2].cpu().data.numpy())\n",
    "        all_labels = np.append(all_labels, labels.numpy())\n",
    "    \n",
    "    plt.ion()  # Enable interactive mode\n",
    "    \n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    scatter = ax.scatter(z_means_x, z_means_y, z_means_z, c=all_labels, cmap='inferno', s=1)\n",
    "    \n",
    "    ax.set_xlabel('Latent Dimension 1')\n",
    "    ax.set_ylabel('Latent Dimension 2')\n",
    "    ax.set_zlabel('Latent Dimension 3')\n",
    "    \n",
    "    fig.colorbar(scatter, ax=ax, shrink=0.5, aspect=5)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "visualize_encoder_3d(model3, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Visualize digits generated from latent space grid\n",
    "def visualize_decoder(model,num=20,range_type='g'):\n",
    "    image_grid = np.zeros([num*28,num*28])\n",
    "\n",
    "    if range_type == 'l': # linear range\n",
    "        # corresponds to output range of visualize_encoding()\n",
    "        range_space = np.linspace(-4,4,num)\n",
    "    elif range_type == 'g': # gaussian range\n",
    "        range_space = norm.ppf(np.linspace(0.01,0.99,num))\n",
    "    else:\n",
    "        range_space = range_type\n",
    "\n",
    "    for i, x in enumerate(range_space):\n",
    "        for j, y in enumerate(reversed(range_space)):\n",
    "            z = Variable(torch.FloatTensor([[x,y]]))\n",
    "            image = model.decoder(z.to(device))\n",
    "            image = image.cpu().data.numpy()\n",
    "            image_grid[(j*28):((j+1)*28),(i*28):((i+1)*28)] = image\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image_grid)\n",
    "    plt.show\n",
    "    return range_space\n",
    "\n",
    "range_space = visualize_decoder(model2, range_type='l')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "widgets": {
   "state": {
    "15c130142e894d2ca785cf26583373b8": {
     "views": [
      {
       "cell_index": 6
      }
     ]
    },
    "93aa83e9363d4d08876f64d1c32ed55e": {
     "views": [
      {
       "cell_index": 10
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
